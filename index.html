<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=600" />
    <title>Alpha-to-Coverage Emulator</title>
    <style>
      :root {
        color-scheme: dark;
      }
      * {
        box-sizing: border-box;
      }
      html,
      body {
        margin: 0; /* remove default margin */
        height: 100%; /* make body fill the browser window */
      }
      body {
        overflow-x: hidden;
        overflow-y: scroll;
      }

      #left,
      #right {
        position: fixed;
        top: 0;
      }
      #left {
        left: 0;
        width: 70vw;
        height: 100vh;
      }
      #right {
        position: absolute;
        right: 0;
        width: 30vw;
        min-width: 200px;
        padding: 0.5em 0.5em 90vh 0.5em;
        overflow-wrap: anywhere;
        background: rgb(0 0 0 / 50%);
      }

      canvas {
        width: calc(min(70vw, 100vh) - 1em);
        height: calc(min(70vw, 100vh) - 1em);
        display: block;
        position: absolute;
        left: 0.5em;
        bottom: 0.5em;
      }
      #guibox {
        position: absolute;
        top: 0;
        right: 0;
      }

      /* target of the current url#hash */
      :target {
        color: green;
        text-decoration-style: wavy;
      }

      .more {
        display: inline-block;
        font-size: 24pt;
        transform: scaleY(50%);
        transform-origin: 0 12pt;
        letter-spacing: 1pt;
        line-height: 12px;
      }
    </style>
    <script defer type="module" src="./main.js"></script>
  </head>
  <body>
    <div id="left">
      <canvas></canvas>
      <div id="guibox"></div>
    </div>
    <div id="right">
      <h1>Alpha-to-Coverage Inspector/Emulator</h1>

      <p>
        Alpha-to-coverage is a GPU hardware feature which approximates
        alpha-blending using MSAA (multi-sample antialiasing) &mdash;
        essentially an anti-aliased version of alpha-testing, as a cheap
        alternative to order-independent transparency (OIT) techniques.
      </p>
      <p>
        This article is an interactive visualization based on
        <a
          href="https://bgolus.medium.com/anti-aliased-alpha-test-the-esoteric-alpha-to-coverage-8b177335ae4f"
          ><em>Anti-aliased Alpha Test: The Esoteric Alpha To Coverage</em></a
        >
        by Ben Golus.
      </p>
      <p>
        The source of this demo is
        <a href="https://github.com/kainino0x/alpha-to-coverage-emulator"
          >on GitHub</a
        >!
      </p>
      <p>
        There are several components to this demo/visualization. They are
        demonstrated in various "presets", each with an accompanying section of
        the article. The resolution of the visualization defaults to one where
        you can clearly see the resulting pixels. At any time you can adjust any
        of the options &mdash; including the resolution, using the "size"
        slider, which goes from 1&times;1 to 8192&times;8192 (up to your canvas
        resolution).
      </p>

      <h2>
        Click the header links (or the buttons under "presets" on the left) to
        activate each preset from the article!
      </h2>

      <hr />

      <h2><a id="foliageA2C">loading...</a></h2>
      <p>
        This is a visualization of a "bush" made of "leaves" using my
        understanding of the alpha-to-coverage technique described by Golus.
      </p>

      <h2><a id="foliageAlphaTest">loading...</a></h2>
      <p>
        And this is the aliased version of the same thing &mdash; using
        alpha-testing instead of alpha-to-coverage.
      </p>

      <h2><a id="foliageBlend">loading...</a></h2>
      <p>
        Just for fun, this shows the bush rendered using alpha-blending without
        any kind of order-independent transparency. The leaves are painted in
        entirely the wrong order.
      </p>

      <h2><a id="oneGradientBlend">loading...</a></h2>
      <p>
        Now, let's dive into some scenes that show how alpha-to-coverage works.
        We'll do this by rendering a few transparency-gradients on top of each
        other. This scene renders one white quad (on a black background) with an
        alpha gradient from 0% at the top to 100% at the bottom...
      </p>

      <h2><a id="overlappingGradientsBlend">loading...</a></h2>
      <p>
        ... and this scene plops a <em>black</em> quad on top, this time with an
        alpha gradient from 0% on the let to 100% on the right.
      </p>
      <p>
        Here we can see the "ideal" result for this scene. However,
        alpha-blending is order-dependent, so this only works because we have
        drawn our geometry in the correct order. Instead, we would like to avoid
        blending, so that we can rely on the depth test to "sort" our geometry
        for us.
      </p>

      <h2><a id="overlappingGradientsAlphaTest">loading...</a></h2>
      <p>
        A simple alpha-test (displaying a fragment if alpha &gt; 50%, and
        discarding it if alpha &lt; 50%)... sort of works, but the quality (in a
        scene like this) is extremely low.
      </p>
      <p>
        But we're using MSAA! We don't have to deal in binaries &mdash; if this
        were real geometry, we wouldn't have to answer "yes"/"no" for whether
        each pixel is covered by the geometry. Instead, each of the samples in
        each pixel would have its own coverage bit. Let's zoom in...
      </p>

      <h2><a id="overlappingGradientsAlphaTestZoomed">loading...</a></h2>
      <p>
        Here, we can see each individual sample in our 4xMSAA render target. We
        have quite a bit more resolution to work with. In the fragment shader
        (which runs just once per pixel), we can actually output a "sample mask"
        which tells the GPU which individual samples to keep/discard &mdash;
        without having to run the fragment shader once for every sample (which
        is also possible). We can see that the alpha-test is essentially
        producing either a sample mask of <code>0000</code> or
        <code>1111</code>. But we could output 1, 2, or 3 samples as well...
      </p>

      <h2><a id="overlappingGradientsA2CNVIDIAZoomed">loading...</a></h2>
      <p>
        ... which is exactly what alpha-to-coverage will do for us! Here, we see
        our first real alpha-to-coverage algorithm, the one used by some NVIDIA
        GPUs.
      </p>
      <p>
        (Note the samples are arranged somewhat arbitrarily; that's OK, because
        all the samples for a pixel get averaged together in the end anyway.)
      </p>

      <h2>
        <a id="overlappingGradientsA2CNVIDIAZoomedResolved">loading...</a>
      </h2>
      <p>
        When we average out the samples, we get results that look like this.
        That's sort of a gradient!
      </p>

      <h2><a id="overlappingGradientsA2CNVIDIA">loading...</a></h2>
      <p>Now we can zoom out and see the higher-resolution result.</p>
      <p>
        Well... it's alright, but it still looks pretty chunky. After all, with
        4 bits, there are only 5 values we can work with (0, 1, 2, 3, or 4
        samples covered). Some GPU architectures improve this by applying
        dithering patterns that repeat over 2&times;2 or even 4&times;4 pixel
        areas, providing average "bit depths" of 16 or 64, respectively.
      </p>

      <h2><a id="overlappingGradientsA2CApple">loading...</a></h2>
      <p>
        Let's look at a different GPU architecture. This is the 2&times;2
        dithered alpha-to-coverage pattern used by some Apple GPUs. Much better!
        But notice that the gradient is cut off at the diagonal &mdash; in the
        "ideal" version, this wasn't the case.
      </p>

      <h2><a id="solidInspectorApple">loading...</a></h2>
      <p>
        A different visualization can help us understand why this happens. Here,
        we are looking at a single solid blue quad at varying alpha values. This
        lets us see how the architecture translates alpha values into exact
        bitmask patterns.
      </p>
      <p>
        Note in particular how, on this architecture, once a sample "pops in",
        it never "pops out". This means that for two alpha values
        <code>a1</code> and <code>a2</code>, if <code>a2 &gt; a1</code>,
        <code>a2</code> will <em>always fully cover up</em> <code>a2</code>.
        This is not what would be expected with blending!
      </p>

      <h2><a id="solidInspectorAMD">loading...</a></h2>
      <p>
        Some architectures get a bit fancier to produce somewhat more
        blending-like results. Here is the algorithm used by some AMD GPUs. Note
        how it divides alpha into more than 17 steps (29 to be exact), even
        though it only uses the 16 sample bits over a 2&times;2 area. Instead,
        it "moves" coverage bits around, seemingly arbitrarily, at steps where
        it doesn't change the overall coverage percentage.
      </p>

      <h2><a id="overlappingGradientsA2CAMD">loading...</a></h2>
      <p>
        But this fixes the problem we observed previously! Now, some of those
        more-transparent <code>a1</code> samples show through under
        less-transparent <code>a2</code> samples.
      </p>
      <p>
        Effectively, this technique somewhat randomizes the mixing of nearby
        colors, using slight differences in alpha (that would be barely
        perceptible) as a source of "randomness". It's not perfect, and it has
        some odd artifacts, but it does put us much closer to the blended
        result.
      </p>

      <h2><a id="solidInspectorQualcomm">loading...</a></h2>
      <p>
        What could we do with <em class="more">more</em>? Here's the pattern
        used by some Qualcomm GPUs. It's 4&times;4 (so 64 samples), yet has
        (just) 18 steps.
      </p>

      <h2><a id="overlappingGradientsA2CQualcomm">loading...</a></h2>
      <p>
        And here's how it renders! Pretty cool! <em>Still</em> some artifacts,
        but they easily disappear in a real scene. (The "blurry foliage" preset
        below will show how this actually works nicely in practice!)
      </p>

      <h2><a id="blurryLeafNVIDIA">loading...</a></h2>
      <p>
        This circular gradient scene shows the banding/dithering in a more
        natural scenario. Here on NVIDIA, with banding...
      </p>

      <h2><a id="blurryLeafApple">loading...</a></h2>
      <p>
        ... here on Apple, with 2&times;2 dithering (AMD looks about the same
        because there is only one draw call here)...
      </p>

      <h2><a id="blurryLeafQualcomm">loading...</a></h2>
      <p>... here on Qualcomm, with 4&times;4 dithering...</p>

      <h2><a id="blurryLeafNative">loading...</a></h2>
      <p>
        ... and here on your own GPU's native alpha-to-coverage algorithm (which
        may or may not be the same as one of the above).
      </p>

      <hr />

      <h2><a id="foliageBlurry">loading...</a></h2>
      <p>Finally, a slight variation on the initial demo.</p>
      <p>
        By default, the foliage demo uses a 1px feathered edge to produce an
        antialiased but sharp edge. But at full resolution, the foliage demo
        also looks neat with blurry-edged leaves, shown here.
      </p>
      <p>
        <strong>
          Try out various emulated devices &mdash; they make a subtle
          difference!
        </strong>
        Note in particular how both AMD and Qualcomm (especially Qualcomm) are
        brighter toward the center of the plant where there are a lot more
        overlapping leaves. This is because their algorithms do a better job
        preserving coverage of one leaf before drawing the next one. (I believe
        this technically comes at the cost of some depth-testing accuracy due to
        the randomization, but it's not really noticeable.)
      </p>

      <hr />

      <h2>Technical Notes</h2>

      <ul>
        <li>
          The visualizer uses some ShaderToy-style shader math in order to
          visualize the contents of MSAA textures. It's very simple: we assume
          the hardware uses the standard sample layout, and when rendering in a
          circle around each of those points, we <code>textureLoad</code> from
          the corresponding sample index and display that. Outside of those
          circles, we show the color from the single-sampled resolve target
          (which averages the 4 samples), or the grid lines.
        </li>
        <li>
          This sample only supports 4xMSAA, because WebGPU only supports 4xMSAA.
          Someday it will support more!
        </li>
        <li>
          Emulation is very simple: instead of enabling alpha-to-coverage, we
          disable it and output the <code>sample_mask</code> builtin instead,
          with alpha set to 1. The sample mask is generated by a function which
          carefully emulates the behavior of some tested hardware. Figuring out
          this function is the hard part...
        </li>
      </ul>

      <h2><a id="generator">loading...</a></h2>
      <p>
        This tool captures the alpha-to-coverage behavior on the current device
        and then attempts to generate code to emulate it, by detecting the block
        size and the exact thresholds beween steps. Click on the "<strong
          >Generate an emulator for this device</strong
        >" button to run the generator.
      </p>
      <p>
        This preset will show the generated emulator in the visualization, and
        <em>also</em> show your native device as a small dot inside the big one
        as a comparison. If you can still see the small dot after clicking the
        button, that means the generated emulator did <em>not</em> successfully
        capture your device's behavior.
        <strong>
          If that happens, or your device has a different pattern than any of
          the ones I have provided, please submit your result!
        </strong>
      </p>
    </div>
  </body>
</html>
